{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exam4-cong.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5Dgiq/mCYa6tQqn41V1Lb"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IivuTJmo_RyL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595127747489,"user_tz":-540,"elapsed":180745,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"90ef83c7-6458-4029-ea6c-cc935e6aefe2"},"source":["# ======================================================================\n","# There are 5 questions in this exam with increasing difficulty from 1-5.\n","# Please note that the weight of the grade for the question is relative\n","# to its difficulty. So your Category 1 question will score significantly\n","# less than your Category 5 question.\n","#\n","# Don't use lambda layers in your model.\n","# You do not need them to solve the question.\n","# Lambda layers are not supported by the grading infrastructure.\n","#\n","# You must use the Submit and Test button to submit your model\n","# at least once in this category before you finally submit your exam,\n","# otherwise you will score zero for this category.\n","# ======================================================================\n","#\n","# NLP QUESTION\n","#\n","# Build and train a classifier for the sarcasm dataset.\n","# The classifier should have a final layer with 1 neuron activated by sigmoid as shown.\n","# It will be tested against a number of sentences that the network hasn't previously seen\n","# and you will be scored on whether sarcasm was correctly detected in those sentences.\n","\n","import json\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'\n","    urllib.request.urlretrieve(url, 'sarcasm.json')\n","\n","    with open(\"./sarcasm.json\", 'r') as f:\n","        datastore = json.load(f)\n","    # DO NOT CHANGE THIS CODE OR THE TESTS MAY NOT WORK\n","    vocab_size = 1000\n","    embedding_dim = 16\n","    max_length = 120\n","    trunc_type='post'\n","    padding_type='post'\n","    oov_tok = \"<OOV>\"\n","    training_size = 20000\n","\n","    sentences = []\n","    labels = []\n","\n","    # YOUR CODE HERE\n","    for item in datastore:\n","      sentences.append(item['headline'])\n","      labels.append(item['is_sarcastic'])\n","\n","    training_sentences = sentences[0:training_size]\n","    testing_sentences = sentences[training_size:]\n","    training_labels = labels[0:training_size]\n","    testing_labels = labels[training_size:]\n","\n","    tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n","    tokenizer.fit_on_texts(training_sentences)\n","\n","    word_index = tokenizer.word_index\n","\n","    training_sequences = tokenizer.texts_to_sequences(training_sentences)\n","    training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","    testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n","    testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n","\n","    training_padded = np.array(training_padded)\n","    training_labels = np.array(training_labels)\n","    testing_padded = np.array(testing_padded)\n","    testing_labels = np.array(testing_labels)\n","\n","\n","    # model = tf.keras.Sequential([\n","    # # YOUR CODE HERE. KEEP THIS OUTPUT LAYER INTACT OR TESTS MAY FAIL\n","    #     tf.keras.layers.Dense(1, activation='sigmoid')\n","    # ])\n","    model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size , embedding_dim, input_length=max_length),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(16, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(10, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')])\n","\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n","    model.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n","    num_epochs = 100\n","    model.fit(training_padded, training_labels, epochs=num_epochs, validation_data=(testing_padded, testing_labels), verbose=2)\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, your saved .h5 model will\n","# be sent to the testing infrastructure for scoring\n","# and the score will be returned to you.\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","625/625 - 2s - loss: 0.6870 - accuracy: 0.5601 - val_loss: 0.6841 - val_accuracy: 0.5633\n","Epoch 2/100\n","625/625 - 2s - loss: 0.6837 - accuracy: 0.5603 - val_loss: 0.6785 - val_accuracy: 0.5633\n","Epoch 3/100\n","625/625 - 2s - loss: 0.6654 - accuracy: 0.5659 - val_loss: 0.6347 - val_accuracy: 0.6244\n","Epoch 4/100\n","625/625 - 2s - loss: 0.6047 - accuracy: 0.6650 - val_loss: 0.5397 - val_accuracy: 0.7626\n","Epoch 5/100\n","625/625 - 2s - loss: 0.5341 - accuracy: 0.7401 - val_loss: 0.4776 - val_accuracy: 0.7991\n","Epoch 6/100\n","625/625 - 2s - loss: 0.4894 - accuracy: 0.7721 - val_loss: 0.4446 - val_accuracy: 0.8068\n","Epoch 7/100\n","625/625 - 2s - loss: 0.4558 - accuracy: 0.7965 - val_loss: 0.4240 - val_accuracy: 0.8038\n","Epoch 8/100\n","625/625 - 2s - loss: 0.4370 - accuracy: 0.7991 - val_loss: 0.4105 - val_accuracy: 0.8126\n","Epoch 9/100\n","625/625 - 2s - loss: 0.4222 - accuracy: 0.8134 - val_loss: 0.4016 - val_accuracy: 0.8183\n","Epoch 10/100\n","625/625 - 2s - loss: 0.4101 - accuracy: 0.8188 - val_loss: 0.3958 - val_accuracy: 0.8195\n","Epoch 11/100\n","625/625 - 2s - loss: 0.4031 - accuracy: 0.8271 - val_loss: 0.3914 - val_accuracy: 0.8207\n","Epoch 12/100\n","625/625 - 2s - loss: 0.3945 - accuracy: 0.8317 - val_loss: 0.3869 - val_accuracy: 0.8237\n","Epoch 13/100\n","625/625 - 2s - loss: 0.3871 - accuracy: 0.8320 - val_loss: 0.3846 - val_accuracy: 0.8229\n","Epoch 14/100\n","625/625 - 2s - loss: 0.3808 - accuracy: 0.8378 - val_loss: 0.3811 - val_accuracy: 0.8247\n","Epoch 15/100\n","625/625 - 2s - loss: 0.3772 - accuracy: 0.8400 - val_loss: 0.3786 - val_accuracy: 0.8267\n","Epoch 16/100\n","625/625 - 2s - loss: 0.3731 - accuracy: 0.8421 - val_loss: 0.3774 - val_accuracy: 0.8296\n","Epoch 17/100\n","625/625 - 2s - loss: 0.3652 - accuracy: 0.8444 - val_loss: 0.3754 - val_accuracy: 0.8278\n","Epoch 18/100\n","625/625 - 2s - loss: 0.3663 - accuracy: 0.8442 - val_loss: 0.3728 - val_accuracy: 0.8313\n","Epoch 19/100\n","625/625 - 2s - loss: 0.3637 - accuracy: 0.8451 - val_loss: 0.3722 - val_accuracy: 0.8325\n","Epoch 20/100\n","625/625 - 2s - loss: 0.3598 - accuracy: 0.8463 - val_loss: 0.3709 - val_accuracy: 0.8302\n","Epoch 21/100\n","625/625 - 2s - loss: 0.3528 - accuracy: 0.8490 - val_loss: 0.3694 - val_accuracy: 0.8316\n","Epoch 22/100\n","625/625 - 2s - loss: 0.3533 - accuracy: 0.8491 - val_loss: 0.3684 - val_accuracy: 0.8326\n","Epoch 23/100\n","625/625 - 2s - loss: 0.3479 - accuracy: 0.8522 - val_loss: 0.3694 - val_accuracy: 0.8335\n","Epoch 24/100\n","625/625 - 2s - loss: 0.3477 - accuracy: 0.8551 - val_loss: 0.3675 - val_accuracy: 0.8332\n","Epoch 25/100\n","625/625 - 2s - loss: 0.3422 - accuracy: 0.8541 - val_loss: 0.3669 - val_accuracy: 0.8347\n","Epoch 26/100\n","625/625 - 2s - loss: 0.3420 - accuracy: 0.8558 - val_loss: 0.3663 - val_accuracy: 0.8353\n","Epoch 27/100\n","625/625 - 2s - loss: 0.3417 - accuracy: 0.8562 - val_loss: 0.3666 - val_accuracy: 0.8347\n","Epoch 28/100\n","625/625 - 2s - loss: 0.3392 - accuracy: 0.8554 - val_loss: 0.3654 - val_accuracy: 0.8347\n","Epoch 29/100\n","625/625 - 2s - loss: 0.3361 - accuracy: 0.8578 - val_loss: 0.3655 - val_accuracy: 0.8344\n","Epoch 30/100\n","625/625 - 2s - loss: 0.3369 - accuracy: 0.8573 - val_loss: 0.3645 - val_accuracy: 0.8366\n","Epoch 31/100\n","625/625 - 2s - loss: 0.3339 - accuracy: 0.8590 - val_loss: 0.3647 - val_accuracy: 0.8346\n","Epoch 32/100\n","625/625 - 2s - loss: 0.3326 - accuracy: 0.8592 - val_loss: 0.3643 - val_accuracy: 0.8353\n","Epoch 33/100\n","625/625 - 2s - loss: 0.3285 - accuracy: 0.8639 - val_loss: 0.3648 - val_accuracy: 0.8343\n","Epoch 34/100\n","625/625 - 2s - loss: 0.3303 - accuracy: 0.8611 - val_loss: 0.3651 - val_accuracy: 0.8356\n","Epoch 35/100\n","625/625 - 2s - loss: 0.3260 - accuracy: 0.8626 - val_loss: 0.3650 - val_accuracy: 0.8368\n","Epoch 36/100\n","625/625 - 2s - loss: 0.3272 - accuracy: 0.8613 - val_loss: 0.3660 - val_accuracy: 0.8371\n","Epoch 37/100\n","625/625 - 2s - loss: 0.3239 - accuracy: 0.8622 - val_loss: 0.3649 - val_accuracy: 0.8371\n","Epoch 38/100\n","625/625 - 2s - loss: 0.3224 - accuracy: 0.8627 - val_loss: 0.3645 - val_accuracy: 0.8369\n","Epoch 39/100\n","625/625 - 2s - loss: 0.3215 - accuracy: 0.8633 - val_loss: 0.3669 - val_accuracy: 0.8344\n","Epoch 40/100\n","625/625 - 2s - loss: 0.3180 - accuracy: 0.8678 - val_loss: 0.3683 - val_accuracy: 0.8384\n","Epoch 41/100\n","625/625 - 2s - loss: 0.3187 - accuracy: 0.8662 - val_loss: 0.3665 - val_accuracy: 0.8351\n","Epoch 42/100\n","625/625 - 2s - loss: 0.3183 - accuracy: 0.8654 - val_loss: 0.3662 - val_accuracy: 0.8353\n","Epoch 43/100\n","625/625 - 2s - loss: 0.3147 - accuracy: 0.8677 - val_loss: 0.3662 - val_accuracy: 0.8374\n","Epoch 44/100\n","625/625 - 2s - loss: 0.3143 - accuracy: 0.8672 - val_loss: 0.3657 - val_accuracy: 0.8356\n","Epoch 45/100\n","625/625 - 2s - loss: 0.3145 - accuracy: 0.8681 - val_loss: 0.3654 - val_accuracy: 0.8362\n","Epoch 46/100\n","625/625 - 2s - loss: 0.3131 - accuracy: 0.8684 - val_loss: 0.3670 - val_accuracy: 0.8334\n","Epoch 47/100\n","625/625 - 2s - loss: 0.3083 - accuracy: 0.8697 - val_loss: 0.3679 - val_accuracy: 0.8351\n","Epoch 48/100\n","625/625 - 2s - loss: 0.3115 - accuracy: 0.8679 - val_loss: 0.3672 - val_accuracy: 0.8362\n","Epoch 49/100\n","625/625 - 2s - loss: 0.3135 - accuracy: 0.8702 - val_loss: 0.3661 - val_accuracy: 0.8365\n","Epoch 50/100\n","625/625 - 2s - loss: 0.3099 - accuracy: 0.8695 - val_loss: 0.3661 - val_accuracy: 0.8356\n","Epoch 51/100\n","625/625 - 2s - loss: 0.3129 - accuracy: 0.8682 - val_loss: 0.3690 - val_accuracy: 0.8357\n","Epoch 52/100\n","625/625 - 2s - loss: 0.3054 - accuracy: 0.8698 - val_loss: 0.3706 - val_accuracy: 0.8351\n","Epoch 53/100\n","625/625 - 2s - loss: 0.3059 - accuracy: 0.8720 - val_loss: 0.3698 - val_accuracy: 0.8359\n","Epoch 54/100\n","625/625 - 2s - loss: 0.3050 - accuracy: 0.8702 - val_loss: 0.3716 - val_accuracy: 0.8348\n","Epoch 55/100\n","625/625 - 2s - loss: 0.3062 - accuracy: 0.8685 - val_loss: 0.3720 - val_accuracy: 0.8341\n","Epoch 56/100\n","625/625 - 2s - loss: 0.3104 - accuracy: 0.8663 - val_loss: 0.3682 - val_accuracy: 0.8354\n","Epoch 57/100\n","625/625 - 2s - loss: 0.3055 - accuracy: 0.8693 - val_loss: 0.3707 - val_accuracy: 0.8351\n","Epoch 58/100\n","625/625 - 2s - loss: 0.3035 - accuracy: 0.8710 - val_loss: 0.3711 - val_accuracy: 0.8347\n","Epoch 59/100\n","625/625 - 2s - loss: 0.3089 - accuracy: 0.8705 - val_loss: 0.3697 - val_accuracy: 0.8354\n","Epoch 60/100\n","625/625 - 2s - loss: 0.2982 - accuracy: 0.8737 - val_loss: 0.3748 - val_accuracy: 0.8351\n","Epoch 61/100\n","625/625 - 2s - loss: 0.2993 - accuracy: 0.8741 - val_loss: 0.3739 - val_accuracy: 0.8331\n","Epoch 62/100\n","625/625 - 2s - loss: 0.2964 - accuracy: 0.8741 - val_loss: 0.3740 - val_accuracy: 0.8340\n","Epoch 63/100\n","625/625 - 2s - loss: 0.2989 - accuracy: 0.8716 - val_loss: 0.3745 - val_accuracy: 0.8338\n","Epoch 64/100\n","625/625 - 2s - loss: 0.2953 - accuracy: 0.8763 - val_loss: 0.3726 - val_accuracy: 0.8350\n","Epoch 65/100\n","625/625 - 2s - loss: 0.2998 - accuracy: 0.8745 - val_loss: 0.3737 - val_accuracy: 0.8351\n","Epoch 66/100\n","625/625 - 2s - loss: 0.2977 - accuracy: 0.8760 - val_loss: 0.3747 - val_accuracy: 0.8356\n","Epoch 67/100\n","625/625 - 2s - loss: 0.2959 - accuracy: 0.8760 - val_loss: 0.3747 - val_accuracy: 0.8344\n","Epoch 68/100\n","625/625 - 2s - loss: 0.2935 - accuracy: 0.8746 - val_loss: 0.3762 - val_accuracy: 0.8338\n","Epoch 69/100\n","625/625 - 2s - loss: 0.2979 - accuracy: 0.8726 - val_loss: 0.3758 - val_accuracy: 0.8343\n","Epoch 70/100\n","625/625 - 2s - loss: 0.2928 - accuracy: 0.8758 - val_loss: 0.3760 - val_accuracy: 0.8356\n","Epoch 71/100\n","625/625 - 2s - loss: 0.2913 - accuracy: 0.8767 - val_loss: 0.3745 - val_accuracy: 0.8341\n","Epoch 72/100\n","625/625 - 2s - loss: 0.2929 - accuracy: 0.8770 - val_loss: 0.3772 - val_accuracy: 0.8341\n","Epoch 73/100\n","625/625 - 2s - loss: 0.2877 - accuracy: 0.8776 - val_loss: 0.3797 - val_accuracy: 0.8348\n","Epoch 74/100\n","625/625 - 2s - loss: 0.2928 - accuracy: 0.8742 - val_loss: 0.3762 - val_accuracy: 0.8341\n","Epoch 75/100\n","625/625 - 2s - loss: 0.2870 - accuracy: 0.8790 - val_loss: 0.3774 - val_accuracy: 0.8331\n","Epoch 76/100\n","625/625 - 2s - loss: 0.2897 - accuracy: 0.8770 - val_loss: 0.3783 - val_accuracy: 0.8329\n","Epoch 77/100\n","625/625 - 2s - loss: 0.2940 - accuracy: 0.8745 - val_loss: 0.3778 - val_accuracy: 0.8335\n","Epoch 78/100\n","625/625 - 2s - loss: 0.2856 - accuracy: 0.8776 - val_loss: 0.3798 - val_accuracy: 0.8343\n","Epoch 79/100\n","625/625 - 2s - loss: 0.2867 - accuracy: 0.8773 - val_loss: 0.3821 - val_accuracy: 0.8340\n","Epoch 80/100\n","625/625 - 2s - loss: 0.2888 - accuracy: 0.8778 - val_loss: 0.3829 - val_accuracy: 0.8335\n","Epoch 81/100\n","625/625 - 2s - loss: 0.2875 - accuracy: 0.8778 - val_loss: 0.3834 - val_accuracy: 0.8331\n","Epoch 82/100\n","625/625 - 2s - loss: 0.2860 - accuracy: 0.8786 - val_loss: 0.3799 - val_accuracy: 0.8316\n","Epoch 83/100\n","625/625 - 2s - loss: 0.2915 - accuracy: 0.8748 - val_loss: 0.3799 - val_accuracy: 0.8335\n","Epoch 84/100\n","625/625 - 2s - loss: 0.2858 - accuracy: 0.8796 - val_loss: 0.3822 - val_accuracy: 0.8305\n","Epoch 85/100\n","625/625 - 2s - loss: 0.2853 - accuracy: 0.8773 - val_loss: 0.3818 - val_accuracy: 0.8323\n","Epoch 86/100\n","625/625 - 2s - loss: 0.2829 - accuracy: 0.8802 - val_loss: 0.3813 - val_accuracy: 0.8316\n","Epoch 87/100\n","625/625 - 2s - loss: 0.2866 - accuracy: 0.8805 - val_loss: 0.3846 - val_accuracy: 0.8323\n","Epoch 88/100\n","625/625 - 2s - loss: 0.2844 - accuracy: 0.8795 - val_loss: 0.3821 - val_accuracy: 0.8320\n","Epoch 89/100\n","625/625 - 2s - loss: 0.2841 - accuracy: 0.8814 - val_loss: 0.3866 - val_accuracy: 0.8314\n","Epoch 90/100\n","625/625 - 2s - loss: 0.2813 - accuracy: 0.8816 - val_loss: 0.3818 - val_accuracy: 0.8310\n","Epoch 91/100\n","625/625 - 2s - loss: 0.2804 - accuracy: 0.8821 - val_loss: 0.3854 - val_accuracy: 0.8313\n","Epoch 92/100\n","625/625 - 2s - loss: 0.2831 - accuracy: 0.8793 - val_loss: 0.3846 - val_accuracy: 0.8319\n","Epoch 93/100\n","625/625 - 2s - loss: 0.2800 - accuracy: 0.8824 - val_loss: 0.3873 - val_accuracy: 0.8326\n","Epoch 94/100\n","625/625 - 2s - loss: 0.2836 - accuracy: 0.8788 - val_loss: 0.3846 - val_accuracy: 0.8325\n","Epoch 95/100\n","625/625 - 2s - loss: 0.2771 - accuracy: 0.8816 - val_loss: 0.3853 - val_accuracy: 0.8295\n","Epoch 96/100\n","625/625 - 2s - loss: 0.2807 - accuracy: 0.8818 - val_loss: 0.3837 - val_accuracy: 0.8316\n","Epoch 97/100\n","625/625 - 2s - loss: 0.2850 - accuracy: 0.8798 - val_loss: 0.3845 - val_accuracy: 0.8286\n","Epoch 98/100\n","625/625 - 2s - loss: 0.2794 - accuracy: 0.8792 - val_loss: 0.3827 - val_accuracy: 0.8305\n","Epoch 99/100\n","625/625 - 2s - loss: 0.2730 - accuracy: 0.8834 - val_loss: 0.3894 - val_accuracy: 0.8299\n","Epoch 100/100\n","625/625 - 2s - loss: 0.2784 - accuracy: 0.8816 - val_loss: 0.3875 - val_accuracy: 0.8304\n"],"name":"stdout"}]}]}