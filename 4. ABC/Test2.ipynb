{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tKHtZaSIz9fP","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595077259635,"user_tz":-540,"elapsed":80578,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"da4736a3-c7ba-47d6-fd64-e254f897f31f"},"source":["#Test #2:\n","\n","# Create a classifier for the Fashion MNIST dataset\n","# Note that the test will expect it to classify 10 classes and that the \n","# input shape should be the native size of the Fashion MNIST dataset which is \n","# 28x28 monochrome. Do not resize the data. YOur input layer should accept\n","# (28,28) as the input shape only. If you amend this, the tests will fail.\n","#\n","import tensorflow as tf \n","from tensorflow import  keras\n","def solution_model():\n","    fashion_mnist = tf.keras.datasets.fashion_mnist\n","    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n","\n","    # Normalize \n","    train_images =  train_images/255.0\n","    test_images =  test_images/255.0\n","\n","    # YOUR CODE HERE \n","    model = tf.keras.models.Sequential([\n","        keras.layers.Flatten(input_shape=(28, 28)),\n","        keras.layers.Dense(128, activation='relu'),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(10, activation='softmax'),\n","    ])\n","\n","    # Loss function and optimization \n","    model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","    model.summary()\n","    #Training model\n","    model.fit(train_images, train_labels, epochs=20)\n","    \n","\n","    return model \n","\n","# Note that you'll need to save your model as a .h5 like this\n","# This .h5 will be uploaded to the testing infrastructure\n","# and a score will be returned to you\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"mymodel.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 784)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 128)               100480    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 128)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 101,770\n","Trainable params: 101,770\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.5343 - accuracy: 0.8110\n","Epoch 2/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.4022 - accuracy: 0.8541\n","Epoch 3/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3680 - accuracy: 0.8658\n","Epoch 4/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3474 - accuracy: 0.8729\n","Epoch 5/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3327 - accuracy: 0.8775\n","Epoch 6/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3191 - accuracy: 0.8813\n","Epoch 7/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3090 - accuracy: 0.8845\n","Epoch 8/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.3008 - accuracy: 0.8883\n","Epoch 9/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2931 - accuracy: 0.8910\n","Epoch 10/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2852 - accuracy: 0.8929\n","Epoch 11/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2801 - accuracy: 0.8943\n","Epoch 12/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2719 - accuracy: 0.8977\n","Epoch 13/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2665 - accuracy: 0.9008\n","Epoch 14/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2640 - accuracy: 0.9012\n","Epoch 15/20\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2597 - accuracy: 0.9027\n","Epoch 16/20\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2521 - accuracy: 0.9041\n","Epoch 17/20\n","1875/1875 [==============================] - 4s 2ms/step - loss: 0.2487 - accuracy: 0.9055\n","Epoch 18/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2432 - accuracy: 0.9085\n","Epoch 19/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2426 - accuracy: 0.9075\n","Epoch 20/20\n","1875/1875 [==============================] - 3s 2ms/step - loss: 0.2384 - accuracy: 0.9090\n"],"name":"stdout"}]}]}