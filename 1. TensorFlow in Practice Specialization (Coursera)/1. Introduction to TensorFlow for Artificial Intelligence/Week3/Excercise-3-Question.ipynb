{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Excercise-3-Question.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7Ykm8xf7I7Fyh+bldxF7g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"Ur3_8rhE8hxM","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Y9GBBij8ylP","colab_type":"code","colab":{}},"source":["dataset_mnist = tf.keras.datasets.mnist\n","(train_dataset, train_label), (test_dataset, test_label)= dataset_mnist.load_data()\n","train_dataset=train_dataset.reshape(60000, 28, 28, 1)\n","train_dataset=train_dataset / 255.0\n","test_dataset = test_dataset.reshape(10000, 28, 28, 1)\n","test_dataset=test_dataset/255.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MJnCGa6-9cHX","colab_type":"code","colab":{}},"source":["def train_epoch():\n","  model = tf.keras.Sequential([\n","        tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n","        tf.keras.layers.MaxPooling2D(2, 2),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(256,activation=tf.nn.relu),\n","        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n","])\n","  model.compile(optimizer=tf.optimizers.Adam(),\n","              loss = 'sparse_categorical_crossentropy',\n","              metrics='accuracy')\n","  class myCallback(tf.keras.callbacks.Callback):\n","      def on_epoch_end(self, epoch, logs={}):\n","        if(logs.get('accuracy')>0.998):\n","          print(\"\\nReached 99.8% accuracy so cancelling training!\")\n","          self.model.stop_training = True\n","  callbacks = myCallback()\n","  model.summary()\n","  history= model.fit(train_dataset,train_label,epochs=10, callbacks=[callbacks])\n","  return history.epoch,  history.history['accuracy'][-1]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4HSSRT_9MiE","colab_type":"code","outputId":"46107998-d350-4260-c527-4010eaa4b976","executionInfo":{"status":"error","timestamp":1592141870236,"user_tz":-540,"elapsed":500038,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"colab":{"base_uri":"https://localhost:8080/","height":561}},"source":["train_epoch()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 26, 26, 64)        640       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 10816)             0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 256)               2769152   \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 2,772,362\n","Trainable params: 2,772,362\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/10\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.1280 - accuracy: 0.9611\n","Epoch 2/10\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.0427 - accuracy: 0.9865\n","Epoch 3/10\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.0251 - accuracy: 0.9923\n","Epoch 4/10\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.0164 - accuracy: 0.9949\n","Epoch 5/10\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.0099 - accuracy: 0.9967\n","Epoch 6/10\n","1875/1875 [==============================] - 75s 40ms/step - loss: 0.0083 - accuracy: 0.9973\n","Epoch 7/10\n","1618/1875 [========================>.....] - ETA: 10s - loss: 0.0055 - accuracy: 0.9980"],"name":"stdout"}]}]}