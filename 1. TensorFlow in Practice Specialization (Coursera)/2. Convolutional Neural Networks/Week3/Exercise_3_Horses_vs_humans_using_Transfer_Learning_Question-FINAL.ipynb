{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise_3_Horses_vs_humans_using_Transfer_Learning_Question-FINAL.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKJaQSXkyM10kuxR0QUTPa"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SNxlbTIfUMjP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1592532619448,"user_tz":-540,"elapsed":7544,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"ae8b80fa-664a-4692-f808-82a0802f3a50"},"source":["import os\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorflow.keras import Model\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n","    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","  \n","from tensorflow.keras.applications.inception_v3 import InceptionV3\n","\n","local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n","\n","pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n","                                include_top = False, \n","                                weights = None)\n","\n","pre_trained_model.load_weights(local_weights_file)\n","\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","  \n","# pre_trained_model.summary()\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-06-19 02:10:12--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.31.128, 2607:f8b0:400c:c02::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.31.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 87910968 (84M) [application/x-hdf]\n","Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n","\n","/tmp/inception_v3_w 100%[===================>]  83.84M   164MB/s    in 0.5s    \n","\n","2020-06-19 02:10:13 (164 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Rj07DAFJVXqK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592532628218,"user_tz":-540,"elapsed":675,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"bdea7368-afc8-475f-b5df-2a3596e2e7a8"},"source":["last_layer = pre_trained_model.get_layer('mixed7')\n","print('last layer output shape: ', last_layer.output_shape)\n","last_output = last_layer.output"],"execution_count":7,"outputs":[{"output_type":"stream","text":["last layer output shape:  (None, 7, 7, 768)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C_fBV8dqVpXk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592532630122,"user_tz":-540,"elapsed":670,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}}},"source":["class myCallback(tf.keras.callbacks.Callback):\n","      def on_epoch_end(self, epoch, logs={}):\n","        if(logs.get('accuracy')> 0.95):\n","          print(\"\\nReached 99.9% accuracy so cancelling training!\")\n","          self.model.stop_training = True"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BZO-2_wV8E9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592533075082,"user_tz":-540,"elapsed":1373,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}}},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(last_output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a dropout rate of 0.2\n","x = layers.Dropout(0.2)(x)                  \n","# Add a final sigmoid layer for classification\n","x = layers.Dense  (1, activation='sigmoid')(x)           \n","\n","model = Model( pre_trained_model.input, x) \n","\n","model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'binary_crossentropy', \n","              metrics = ['accuracy'])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_sIYbWlWTaX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1592533083595,"user_tz":-540,"elapsed":5039,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"e791279f-46e5-478c-e09a-e4874f6ba7f0"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n","    -O /tmp/horse-or-human.zip\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n","    -O /tmp/validation-horse-or-human.zip\n","  \n","import os\n","import zipfile\n","\n","local_zip = '/tmp/horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/horse-or-human')\n","local_zip = '/tmp/validation-horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/validation-horse-or-human')\n","zip_ref.close()\n","# Directory with our training horse pictures\n","train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","train_human_dir = os.path.join('/tmp/horse-or-human/humans')\n","\n","# Directory with our training horse pictures\n","validation_horse_dir = os.path.join('/tmp/validation-horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","validation_human_dir = os.path.join('/tmp/validation-horse-or-human/humans')\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["--2020-06-19 02:17:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 2607:f8b0:400c:c12::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 149574867 (143M) [application/zip]\n","Saving to: ‘/tmp/horse-or-human.zip’\n","\n","/tmp/horse-or-human 100%[===================>] 142.65M   180MB/s    in 0.8s    \n","\n","2020-06-19 02:18:00 (180 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n","\n","--2020-06-19 02:18:01--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 2607:f8b0:400c:c13::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11480187 (11M) [application/zip]\n","Saving to: ‘/tmp/validation-horse-or-human.zip’\n","\n","/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n","\n","2020-06-19 02:18:01 (96.4 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_ecBYD4rWegG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592533086690,"user_tz":-540,"elapsed":723,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"c9feb31f-09d4-4f33-dc31-c5c1eeeace5f"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Directory with our training human pictures and horse \n","train_dir = '/tmp/horse-or-human'\n","validation_dir = '/tmp/validation-horse-or-human'\n","#Add our data-augmentation parameters to ImageDataGenerator\n","train_datagen = ImageDataGenerator(rescale = 1./255.,\n","                                   rotation_range = 40,\n","                                   width_shift_range = 0.2,\n","                                   height_shift_range = 0.2,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","# Note that the validation data should not be augmented!\n","test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    batch_size = 20,\n","                                                    class_mode = 'binary', \n","                                                    target_size = (150, 150))     \n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator =  test_datagen.flow_from_directory( validation_dir,\n","                                                          batch_size  = 20,\n","                                                          class_mode  = 'binary', \n","                                                          target_size = (150, 150))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Found 1027 images belonging to 2 classes.\n","Found 256 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qf4aRB3vXbub","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"executionInfo":{"status":"ok","timestamp":1592533141525,"user_tz":-540,"elapsed":5993,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"2e7cc20a-5b95-4509-e67f-5983cfd326cc"},"source":["callbacks = myCallback()\n","history = model.fit_generator(\n","            train_generator,\n","            validation_data = validation_generator,\n","            steps_per_epoch = 3,\n","            epochs = 3,\n","            validation_steps = 1,\n","            verbose = 2,\n","            callbacks=[callbacks])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-18-491db9d6db0a>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use Model.fit, which supports generators.\n","Epoch 1/3\n","\n","Reached 99.9% accuracy so cancelling training!\n","3/3 - 4s - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n"],"name":"stdout"}]}]}