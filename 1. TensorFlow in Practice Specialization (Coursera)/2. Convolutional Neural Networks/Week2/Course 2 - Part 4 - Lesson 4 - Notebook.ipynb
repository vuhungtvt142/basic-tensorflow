{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Course 2 - Part 4 - Lesson 4 - Notebook.ipynb","provenance":[{"file_id":"https://github.com/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%204%20-%20Lesson%204%20-%20Notebook.ipynb","timestamp":1592456256133}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rX8mhOLljYeM"},"source":["##### Copyright 2019 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"BZSlp3DAjdYf","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"RXZT2UsyIVe_","colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"status":"ok","timestamp":1592456529263,"user_tz":-540,"elapsed":5881,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"237e77ac-684a-4d24-db34-4fc203e5b4df"},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n","    -O /tmp/horse-or-human.zip\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\n","    -O /tmp/validation-horse-or-human.zip\n","  \n","import os\n","import zipfile\n","\n","local_zip = '/tmp/horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/horse-or-human')\n","local_zip = '/tmp/validation-horse-or-human.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/validation-horse-or-human')\n","zip_ref.close()\n","# Directory with our training horse pictures\n","train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","train_human_dir = os.path.join('/tmp/horse-or-human/humans')\n","\n","# Directory with our training horse pictures\n","validation_horse_dir = os.path.join('/tmp/validation-horse-or-human/horses')\n","\n","# Directory with our training human pictures\n","validation_human_dir = os.path.join('/tmp/validation-horse-or-human/humans')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-06-18 05:02:06--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.125.128, 2404:6800:4008:c04::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.125.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 149574867 (143M) [application/zip]\n","Saving to: ‘/tmp/horse-or-human.zip’\n","\n","/tmp/horse-or-human 100%[===================>] 142.65M   189MB/s    in 0.8s    \n","\n","2020-06-18 05:02:07 (189 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n","\n","--2020-06-18 05:02:08--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.189.128, 2404:6800:4008:c04::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.189.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 11480187 (11M) [application/zip]\n","Saving to: ‘/tmp/validation-horse-or-human.zip’\n","\n","/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.05s   \n","\n","2020-06-18 05:02:08 (237 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5oqBkNBJmtUv"},"source":["## Building a Small Model from Scratch\n","\n","But before we continue, let's start defining the model:\n","\n","Step 1 will be to import tensorflow."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qvfZg3LQbD-5","colab":{},"executionInfo":{"status":"ok","timestamp":1592456540235,"user_tz":-540,"elapsed":918,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}}},"source":["import tensorflow as tf"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BnhYCP4tdqjC"},"source":["We then add convolutional layers as in the previous example, and flatten the final result to feed into the densely connected layers."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gokG5HKpdtzm"},"source":["Finally we add the densely connected layers. \n","\n","Note that because we are facing a two-class classification problem, i.e. a *binary classification problem*, we will end our network with a [*sigmoid* activation](https://wikipedia.org/wiki/Sigmoid_function), so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PixZ2s5QbYQ3","colab":{},"executionInfo":{"status":"ok","timestamp":1592456560581,"user_tz":-540,"elapsed":962,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}}},"source":["model = tf.keras.models.Sequential([\n","    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n","    tf.keras.layers.MaxPooling2D(2, 2),\n","    # The second convolution\n","    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The third convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # The fifth convolution\n","    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D(2,2),\n","    # Flatten the results to feed into a DNN\n","    tf.keras.layers.Flatten(),\n","    # 512 neuron hidden layer\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YyEkDpOzQyl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":595},"executionInfo":{"status":"ok","timestamp":1592456563018,"user_tz":-540,"elapsed":1046,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"0ba770e4-c409-4433-e650-263c9666d08d"},"source":["model.summary()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 298, 298, 16)      448       \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 149, 149, 16)      0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 147, 147, 32)      4640      \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 73, 73, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 71, 71, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 35, 35, 64)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 33, 33, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 14, 14, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 7, 7, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 3136)              0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               1606144   \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 513       \n","=================================================================\n","Total params: 1,704,097\n","Trainable params: 1,704,097\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8DHWhFP_uhq3","colab":{},"executionInfo":{"status":"ok","timestamp":1592456745608,"user_tz":-540,"elapsed":1009,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}}},"source":["from tensorflow.keras.optimizers import RMSprop\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(lr=1e-4),\n","              metrics=['accuracy'])"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ClebU9NJg99G","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1592456747653,"user_tz":-540,"elapsed":1014,"user":{"displayName":"cong le","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyU4J69Q1Wa1yvFcxM5SYhxFbEMyJge79C_Pf2GQ=s64","userId":"16902361027910566800"}},"outputId":"64370f42-7177-4923-ad4f-37eb727d74e5"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# All images will be rescaled by 1./255\n","train_datagen = ImageDataGenerator(\n","      rescale=1./255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest')\n","\n","validation_datagen = ImageDataGenerator(rescale=1/255)\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","train_generator = train_datagen.flow_from_directory(\n","        '/tmp/horse-or-human/',  # This is the source directory for training images\n","        target_size=(300, 300),  # All images will be resized to 150x150\n","        batch_size=128,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')\n","\n","# Flow training images in batches of 128 using train_datagen generator\n","validation_generator = validation_datagen.flow_from_directory(\n","        '/tmp/validation-horse-or-human/',  # This is the source directory for training images\n","        target_size=(300, 300),  # All images will be resized to 150x150\n","        batch_size=32,\n","        # Since we use binary_crossentropy loss, we need binary labels\n","        class_mode='binary')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Found 1027 images belonging to 2 classes.\n","Found 256 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Fb1_lgobv81m","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"e8a93d77-9c39-4087-d719-76428e7b6f20"},"source":["history = model.fit(\n","      train_generator,\n","      steps_per_epoch=8,  \n","      epochs=100,\n","      verbose=1,\n","      validation_data = validation_generator,\n","      validation_steps=8)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","8/8 [==============================] - 16s 2s/step - loss: 0.6833 - accuracy: 0.5706 - val_loss: 0.6722 - val_accuracy: 0.5234\n","Epoch 2/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.6631 - accuracy: 0.6552 - val_loss: 0.6785 - val_accuracy: 0.5000\n","Epoch 3/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.6305 - accuracy: 0.6863 - val_loss: 0.6099 - val_accuracy: 0.8633\n","Epoch 4/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.5988 - accuracy: 0.7086 - val_loss: 0.6636 - val_accuracy: 0.5156\n","Epoch 5/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.5619 - accuracy: 0.7197 - val_loss: 0.8391 - val_accuracy: 0.5000\n","Epoch 6/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.5913 - accuracy: 0.6796 - val_loss: 0.6946 - val_accuracy: 0.5195\n","Epoch 7/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.5622 - accuracy: 0.7219 - val_loss: 0.7505 - val_accuracy: 0.5078\n","Epoch 8/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.5221 - accuracy: 0.7364 - val_loss: 1.5003 - val_accuracy: 0.5000\n","Epoch 9/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.5233 - accuracy: 0.7575 - val_loss: 0.6778 - val_accuracy: 0.5352\n","Epoch 10/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.5034 - accuracy: 0.7697 - val_loss: 0.7913 - val_accuracy: 0.5391\n","Epoch 11/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4889 - accuracy: 0.7597 - val_loss: 0.6040 - val_accuracy: 0.6250\n","Epoch 12/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.5073 - accuracy: 0.7471 - val_loss: 0.9086 - val_accuracy: 0.5234\n","Epoch 13/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.4591 - accuracy: 0.7871 - val_loss: 0.9035 - val_accuracy: 0.5391\n","Epoch 14/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4863 - accuracy: 0.7642 - val_loss: 1.2372 - val_accuracy: 0.5078\n","Epoch 15/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4894 - accuracy: 0.7475 - val_loss: 0.9631 - val_accuracy: 0.5391\n","Epoch 16/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4165 - accuracy: 0.8176 - val_loss: 0.4574 - val_accuracy: 0.8086\n","Epoch 17/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4783 - accuracy: 0.7675 - val_loss: 0.7906 - val_accuracy: 0.6172\n","Epoch 18/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.4199 - accuracy: 0.8154 - val_loss: 1.2132 - val_accuracy: 0.5391\n","Epoch 19/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4110 - accuracy: 0.8031 - val_loss: 1.2571 - val_accuracy: 0.5391\n","Epoch 20/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3721 - accuracy: 0.8254 - val_loss: 2.1410 - val_accuracy: 0.5000\n","Epoch 21/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.4730 - accuracy: 0.7597 - val_loss: 1.1509 - val_accuracy: 0.5547\n","Epoch 22/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3798 - accuracy: 0.8354 - val_loss: 0.9247 - val_accuracy: 0.6133\n","Epoch 23/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.3644 - accuracy: 0.8311 - val_loss: 2.1029 - val_accuracy: 0.5000\n","Epoch 24/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.4156 - accuracy: 0.8037 - val_loss: 1.8515 - val_accuracy: 0.5000\n","Epoch 25/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.3644 - accuracy: 0.8408 - val_loss: 0.8921 - val_accuracy: 0.6562\n","Epoch 26/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3801 - accuracy: 0.8209 - val_loss: 0.8988 - val_accuracy: 0.6719\n","Epoch 27/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.3656 - accuracy: 0.8311 - val_loss: 0.9527 - val_accuracy: 0.6523\n","Epoch 28/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3698 - accuracy: 0.8265 - val_loss: 1.5256 - val_accuracy: 0.5547\n","Epoch 29/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3649 - accuracy: 0.8311 - val_loss: 1.4721 - val_accuracy: 0.5547\n","Epoch 30/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3990 - accuracy: 0.8409 - val_loss: 1.5117 - val_accuracy: 0.5430\n","Epoch 31/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3055 - accuracy: 0.8750 - val_loss: 2.0383 - val_accuracy: 0.5234\n","Epoch 32/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3874 - accuracy: 0.8287 - val_loss: 1.4365 - val_accuracy: 0.5781\n","Epoch 33/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3549 - accuracy: 0.8387 - val_loss: 1.3870 - val_accuracy: 0.5781\n","Epoch 34/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3765 - accuracy: 0.8376 - val_loss: 1.2960 - val_accuracy: 0.5781\n","Epoch 35/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3121 - accuracy: 0.8799 - val_loss: 1.5823 - val_accuracy: 0.5508\n","Epoch 36/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.2846 - accuracy: 0.8799 - val_loss: 1.8606 - val_accuracy: 0.5352\n","Epoch 37/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3650 - accuracy: 0.8487 - val_loss: 1.6142 - val_accuracy: 0.5508\n","Epoch 38/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3099 - accuracy: 0.8565 - val_loss: 1.8037 - val_accuracy: 0.5508\n","Epoch 39/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3072 - accuracy: 0.8621 - val_loss: 1.7323 - val_accuracy: 0.5586\n","Epoch 40/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3014 - accuracy: 0.8799 - val_loss: 1.5703 - val_accuracy: 0.5859\n","Epoch 41/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3242 - accuracy: 0.8454 - val_loss: 1.2324 - val_accuracy: 0.5977\n","Epoch 42/100\n","8/8 [==============================] - 22s 3s/step - loss: 0.2542 - accuracy: 0.9014 - val_loss: 1.7963 - val_accuracy: 0.5742\n","Epoch 43/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.3364 - accuracy: 0.8331 - val_loss: 1.9267 - val_accuracy: 0.5664\n","Epoch 44/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.3193 - accuracy: 0.8532 - val_loss: 1.4863 - val_accuracy: 0.5625\n","Epoch 45/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.2748 - accuracy: 0.8776 - val_loss: 1.6046 - val_accuracy: 0.5820\n","Epoch 46/100\n","8/8 [==============================] - 22s 3s/step - loss: 0.2576 - accuracy: 0.8906 - val_loss: 1.5143 - val_accuracy: 0.5938\n","Epoch 47/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.2597 - accuracy: 0.9010 - val_loss: 1.4958 - val_accuracy: 0.5898\n","Epoch 48/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.4079 - accuracy: 0.8432 - val_loss: 1.4415 - val_accuracy: 0.5703\n","Epoch 49/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3363 - accuracy: 0.8610 - val_loss: 1.3999 - val_accuracy: 0.6133\n","Epoch 50/100\n","8/8 [==============================] - 19s 2s/step - loss: 0.2309 - accuracy: 0.9121 - val_loss: 2.1202 - val_accuracy: 0.5547\n","Epoch 51/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.3826 - accuracy: 0.8565 - val_loss: 1.7258 - val_accuracy: 0.5781\n","Epoch 52/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2089 - accuracy: 0.9277 - val_loss: 2.1906 - val_accuracy: 0.5273\n","Epoch 53/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2565 - accuracy: 0.8954 - val_loss: 2.3660 - val_accuracy: 0.5195\n","Epoch 54/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2732 - accuracy: 0.8865 - val_loss: 1.7260 - val_accuracy: 0.5781\n","Epoch 55/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2152 - accuracy: 0.9221 - val_loss: 3.6797 - val_accuracy: 0.5078\n","Epoch 56/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3098 - accuracy: 0.8643 - val_loss: 1.5766 - val_accuracy: 0.5898\n","Epoch 57/100\n","8/8 [==============================] - 20s 3s/step - loss: 0.2493 - accuracy: 0.9053 - val_loss: 1.9983 - val_accuracy: 0.5469\n","Epoch 58/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3120 - accuracy: 0.8966 - val_loss: 1.6325 - val_accuracy: 0.5742\n","Epoch 59/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2169 - accuracy: 0.9132 - val_loss: 2.5922 - val_accuracy: 0.5156\n","Epoch 60/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2419 - accuracy: 0.9055 - val_loss: 2.0353 - val_accuracy: 0.5508\n","Epoch 61/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2317 - accuracy: 0.9055 - val_loss: 1.5384 - val_accuracy: 0.6172\n","Epoch 62/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2306 - accuracy: 0.9010 - val_loss: 2.3655 - val_accuracy: 0.5273\n","Epoch 63/100\n","8/8 [==============================] - 21s 3s/step - loss: 0.2424 - accuracy: 0.9099 - val_loss: 2.0670 - val_accuracy: 0.5430\n","Epoch 64/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2270 - accuracy: 0.9199 - val_loss: 2.4112 - val_accuracy: 0.5273\n","Epoch 65/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2014 - accuracy: 0.9188 - val_loss: 2.6179 - val_accuracy: 0.5273\n","Epoch 66/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2282 - accuracy: 0.9010 - val_loss: 3.5270 - val_accuracy: 0.5000\n","Epoch 67/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.2239 - accuracy: 0.9099 - val_loss: 2.2787 - val_accuracy: 0.5508\n","Epoch 68/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.3379 - accuracy: 0.8598 - val_loss: 2.0107 - val_accuracy: 0.5352\n","Epoch 69/100\n","8/8 [==============================] - 18s 2s/step - loss: 0.1882 - accuracy: 0.9299 - val_loss: 2.7625 - val_accuracy: 0.5156\n","Epoch 70/100\n","1/8 [==>...........................] - ETA: 0s - loss: 0.0374 - accuracy: 1.0000"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7zNPRWOVJdOH","colab":{}},"source":["import matplotlib.pyplot as plt\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'r', label='Training accuracy')\n","plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'r', label='Training Loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}